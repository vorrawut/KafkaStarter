spring:
  application:
    name: kafka-streams-lesson16

  # Kafka configuration for Lesson 16 - State Stores & Fault Tolerance
  kafka:
    bootstrap-servers: localhost:9092
    
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: all
      retries: 3
      properties:
        enable.idempotence: true
    
    consumer:
      group-id: lesson16-consumer-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      auto-offset-reset: earliest
      properties:
        spring.json.trusted.packages: "com.learning.KafkaStarter.model"
    
    streams:
      application-id: lesson16-state-stores-app
      state-dir: /tmp/kafka-streams/lesson16
      replication-factor: 3  # Increased for fault tolerance
      num-standby-replicas: 2  # Enable standby replicas
      default:
        key:
          serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        value:
          serde: org.springframework.kafka.support.serializer.JsonSerde
      properties:
        processing.guarantee: exactly_once_v2
        commit.interval.ms: 10000
        cache.max.bytes.buffering: 10485760  # 10MB
        num.stream.threads: 3
        acceptable.recovery.lag: 1000
        default.deserialization.exception.handler: org.apache.kafka.streams.errors.LogAndContinueExceptionHandler

server:
  port: 8093

logging:
  level:
    com.learning.KafkaStarter: DEBUG
    org.apache.kafka.streams: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,kafka
  endpoint:
    health:
      show-details: always